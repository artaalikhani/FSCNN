{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import time\n",
        "\n",
        "from FSCNN import Net\n",
        "\n",
        "global case_study\n",
        "\n",
        "# Select case study\n",
        "# case_study = 'ITSC'\n",
        "case_study = 'CWRU'\n",
        "# case_study = 'Ottawa'\n",
        "\n",
        "def train_val_test_split(data, labels, split_ratio):\n",
        "    n_samples = data.shape[0]\n",
        "    div1 = int(n_samples * split_ratio)\n",
        "    div2 = div1 + (n_samples - div1) // 2\n",
        "    indices = list(range(n_samples))\n",
        "\n",
        "    if case_study == 'CWRU':\n",
        "        test_ind_file = 'data_test_ind_CWRU.csv'\n",
        "    elif case_study == 'ITSC':\n",
        "        test_ind_file = 'data_test_ind_ITSC.csv'\n",
        "    else:\n",
        "        test_ind_file = 'data_test_ind_Ottawa.csv'\n",
        "\n",
        "    if os.path.isfile(test_ind_file):\n",
        "        indices = np.loadtxt(test_ind_file, delimiter=\",\").astype(int)\n",
        "    else:\n",
        "        indices = np.random.permutation(indices)\n",
        "        np.savetxt(test_ind_file, indices, delimiter=\",\")\n",
        "\n",
        "    data_train = data[indices[:div1]]\n",
        "    data_val = data[indices[div1:div2]]\n",
        "    data_test = data[indices[div2:]]\n",
        "\n",
        "    labels_train = labels[indices[:div1]]\n",
        "    labels_val = labels[indices[div1:div2]]\n",
        "    labels_test = labels[indices[div2:]]\n",
        "\n",
        "    return (data_train, data_val, data_test), (labels_train, labels_val, labels_test)\n",
        "\n",
        "def dataloader_preparation(split_ratio=0.7, batch_size=50):\n",
        "    global num_classes\n",
        "\n",
        "    if case_study == 'CWRU':\n",
        "        datasets = np.loadtxt('Vib_data2.csv', delimiter=\",\")\n",
        "    elif case_study == 'ITSC':\n",
        "        datasets = np.loadtxt('Iq_ITSC_PMSM.csv', delimiter=\",\")\n",
        "    else:\n",
        "        datasets = np.loadtxt('dataset_ottawa.csv', delimiter=\",\")\n",
        "\n",
        "    num_features = datasets.shape[1] - 1\n",
        "    num_classes = len(np.unique(datasets[:, -1]))\n",
        "\n",
        "    data = datasets[:, np.newaxis, :num_features]\n",
        "    labels = datasets[:, -1]\n",
        "\n",
        "    data_split, labels_split = train_val_test_split(data, labels, split_ratio)\n",
        "\n",
        "    dataloader_train = DataLoader(\n",
        "        TensorDataset(torch.tensor(data_split[0], dtype=torch.float32), torch.tensor(labels_split[0], dtype=torch.long)),\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "    )\n",
        "\n",
        "    dataloader_val = DataLoader(\n",
        "        TensorDataset(torch.tensor(data_split[1], dtype=torch.float32), torch.tensor(labels_split[1], dtype=torch.long)),\n",
        "        batch_size=batch_size,\n",
        "    )\n",
        "\n",
        "    dataloader_test = DataLoader(\n",
        "        TensorDataset(torch.tensor(data_split[2], dtype=torch.float32), torch.tensor(labels_split[2], dtype=torch.long)),\n",
        "        batch_size=batch_size,\n",
        "    )\n",
        "\n",
        "    return dataloader_train, dataloader_val, dataloader_test\n",
        "\n",
        "def train(dataloader, device, model, criterion, optimizer):\n",
        "    model.train()\n",
        "    total_loss, total_corrects, n_train = 0.0, 0, 0\n",
        "\n",
        "    for batch in dataloader:\n",
        "        inputs, labels = (t.to(device) for t in batch)\n",
        "        labels = labels.long()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        preds = outputs.argmax(dim=1, keepdim=True)\n",
        "        total_corrects += preds.eq(labels.view_as(preds)).sum().item()\n",
        "        total_loss += loss.item() * labels.size(0)\n",
        "        n_train += labels.size(0)\n",
        "\n",
        "    epoch_loss = total_loss / n_train\n",
        "    epoch_acc = 100.0 * total_corrects / n_train\n",
        "    print(f'Train loss: {epoch_loss:.4f} || Train accuracy: {epoch_acc:.2f}%')\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "def test(dataloader, device, model, criterion):\n",
        "    model.eval()\n",
        "    total_loss, total_corrects, n_test = 0.0, 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            inputs, labels = (t.to(device) for t in batch)\n",
        "            labels = labels.long()\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            preds = outputs.argmax(dim=1, keepdim=True)\n",
        "            total_corrects += preds.eq(labels.view_as(preds)).sum().item()\n",
        "            total_loss += loss.item() * labels.size(0)\n",
        "            n_test += labels.size(0)\n",
        "\n",
        "    epoch_loss = total_loss / n_test\n",
        "    epoch_acc = 100.0 * total_corrects / n_test\n",
        "    print(f'Test loss: {epoch_loss:.4f} || Test accuracy: {epoch_acc:.2f}%')\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    log_file_name = f'results_logged_{case_study}_FSCNN.csv'\n",
        "    n_epoch = 500\n",
        "    batch_size = 32\n",
        "\n",
        "    dataloader_train, dataloader_val, dataloader_test = dataloader_preparation(batch_size=batch_size)\n",
        "    model = Net(n_class=num_classes, case_study=case_study).to(device).double()\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss().to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    best_acc = 0.0\n",
        "    results = np.zeros((n_epoch, 6))\n",
        "\n",
        "    for epoch in range(n_epoch):\n",
        "        print(f'------------------ Epoch {epoch} ------------------')\n",
        "\n",
        "        t0 = time.time()\n",
        "        loss_train, acc_train = train(dataloader_train, device, model, criterion, optimizer)\n",
        "        train_time = time.time() - t0\n",
        "\n",
        "        loss_val, acc_val = test(dataloader_val, device, model, criterion)\n",
        "        test_time = time.time() - t0 - train_time\n",
        "\n",
        "        print(f'Training time: {train_time:.2f}s | Test time: {test_time:.2f}s')\n",
        "\n",
        "        results[epoch, :] = [loss_train, acc_train, loss_val, acc_val, train_time, test_time]\n",
        "        pd.DataFrame(results, columns=['loss_train', 'acc_train', 'loss_val', 'acc_val', 'train_time', 'test_time']).to_csv(log_file_name, index=False)\n",
        "\n",
        "        if acc_val >= best_acc:\n",
        "            best_acc = acc_val\n",
        "            loss_test, acc_test = test(dataloader_test, device, model, criterion)\n",
        "\n",
        "            if acc_train == 100 and acc_val == 100:\n",
        "                model_path = f'./FSCNN_epoch_{case_study}_{epoch}.pt'\n",
        "                torch.save(model.state_dict(), model_path)\n",
        "                print(f'Model saved: {model_path}')"
      ],
      "metadata": {
        "id": "Dtmg11tragH8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "9z4en42F0c1C",
        "wbB1Mn7p0gAU",
        "spujtYDd5J5M",
        "peMIjxx_soiY"
      ],
      "mount_file_id": "1RYzgvHETVHjzPPixGRkqHOCp7ygM8-Y3",
      "authorship_tag": "ABX9TyMtFAMH2UuM9NzgfmDLqc2f"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
